{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79b24c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: feedparser in c:\\users\\riddh\\anaconda3\\lib\\site-packages (6.0.8)\n",
      "Requirement already satisfied: sqlalchemy in c:\\users\\riddh\\anaconda3\\lib\\site-packages (1.4.31)\n",
      "Requirement already satisfied: celery in c:\\users\\riddh\\anaconda3\\lib\\site-packages (5.2.3)\n",
      "Requirement already satisfied: nltk in c:\\users\\riddh\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from feedparser) (1.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from sqlalchemy) (1.1.1)\n",
      "Requirement already satisfied: billiard<4.0,>=3.6.4.0 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (3.6.4.0)\n",
      "Requirement already satisfied: click-didyoumean>=0.0.3 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (0.3.0)\n",
      "Requirement already satisfied: click-plugins>=1.1.1 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (1.1.1)\n",
      "Requirement already satisfied: vine<6.0,>=5.0.0 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (5.1.0)\n",
      "Requirement already satisfied: click<9.0,>=8.0.3 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (8.0.3)\n",
      "Requirement already satisfied: pytz>=2021.3 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (2021.3)\n",
      "Requirement already satisfied: kombu<6.0,>=5.2.3 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (5.3.5)\n",
      "Requirement already satisfied: setuptools<59.7.0,>=59.1.1 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (59.6.0)\n",
      "Requirement already satisfied: click-repl>=0.2.0 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from celery) (0.3.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from click<9.0,>=8.0.3->celery) (0.4.4)\n",
      "Requirement already satisfied: prompt-toolkit>=3.0.36 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from click-repl>=0.2.0->celery) (3.0.43)\n",
      "Requirement already satisfied: amqp<6.0.0,>=5.1.1 in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from kombu<6.0,>=5.2.3->celery) (5.2.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from kombu<6.0,>=5.2.3->celery) (3.10.0.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\riddh\\anaconda3\\lib\\site-packages (from prompt-toolkit>=3.0.36->click-repl>=0.2.0->celery) (0.2.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install feedparser sqlalchemy celery nltk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "457d8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "import feedparser\n",
    "from sqlalchemy import create_engine, Column, String, DateTime, text\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from celery import Celery\n",
    "from nltk import download, word_tokenize, NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6950ea7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\riddh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\riddh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download('punkt')\n",
    "download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32861cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base = declarative_base()\n",
    "\n",
    "class NewsArticle(Base):\n",
    "    __tablename__ = 'news_articles'\n",
    "    id = Column(String, primary_key=True)\n",
    "    title = Column(String)\n",
    "    content = Column(String)\n",
    "    pub_date = Column(DateTime)\n",
    "    source_url = Column(String)\n",
    "    category = Column(String)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a590cce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-29 22:28:10,985 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-29 22:28:10,985 INFO sqlalchemy.engine.Engine PRAGMA main.table_info(\"news_articles\")\n",
      "2024-01-29 22:28:10,999 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-01-29 22:28:11,000 INFO sqlalchemy.engine.Engine PRAGMA temp.table_info(\"news_articles\")\n",
      "2024-01-29 22:28:11,001 INFO sqlalchemy.engine.Engine [raw sql] ()\n",
      "2024-01-29 22:28:11,001 INFO sqlalchemy.engine.Engine \n",
      "CREATE TABLE news_articles (\n",
      "\tid VARCHAR NOT NULL, \n",
      "\ttitle VARCHAR, \n",
      "\tcontent VARCHAR, \n",
      "\tpub_date DATETIME, \n",
      "\tsource_url VARCHAR, \n",
      "\tcategory VARCHAR, \n",
      "\tPRIMARY KEY (id)\n",
      ")\n",
      "\n",
      "\n",
      "2024-01-29 22:28:11,001 INFO sqlalchemy.engine.Engine [no key 0.00102s] ()\n",
      "2024-01-29 22:28:11,001 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    }
   ],
   "source": [
    "engine = create_engine('sqlite:///:memory:', echo=True)\n",
    "Base.metadata.create_all(engine)\n",
    "Session = sessionmaker(bind=engine)\n",
    "session = Session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5820795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5c8887b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def extract_features(article_text):\n",
    "    words = word_tokenize(article_text)\n",
    "    return {word: True for word in words if word.lower() not in stop_words}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a77e5e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = [\n",
    "    (\"Terrorism in city\", \"terrorism\"),\n",
    "    (\"Positive story about charity\", \"positive\"),\n",
    "    (\"Natural Disaster\", \"Disaster\"),\n",
    "    (\"Others :)\", \"others\")\n",
    "\n",
    "    # Add more training examples for other categories\n",
    "]\n",
    "\n",
    "classifier = NaiveBayesClassifier.train([(extract_features(text), category) for text, category in training_data])\n",
    "\n",
    "    # Add more training examples for other categories\n",
    "\n",
    "\n",
    "classifier = NaiveBayesClassifier.train([(extract_features(text), category) for text, category in training_data])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "53d1a256",
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.task\n",
    "def process_news_article(article_id, title, content, pub_date, source_url):\n",
    "    # Perform text classification\n",
    "    features = extract_features(title + \" \" + content)\n",
    "    category = classifier.classify(features)\n",
    "\n",
    "    # Update the database with the assigned category\n",
    "    article = NewsArticle(id=article_id, title=title, content=content, pub_date=pub_date, source_url=source_url, category=category)\n",
    "    session.add(article)\n",
    "    session.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2499c9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-01-30 18:23:44,375 INFO sqlalchemy.engine.Engine BEGIN (implicit)\n",
      "2024-01-30 18:23:44,375 INFO sqlalchemy.engine.Engine SELECT news_articles.id AS news_articles_id, news_articles.title AS news_articles_title, news_articles.content AS news_articles_content, news_articles.pub_date AS news_articles_pub_date, news_articles.source_url AS news_articles_source_url, news_articles.category AS news_articles_category \n",
      "FROM news_articles \n",
      "WHERE news_articles.id = ?\n",
      "2024-01-30 18:23:44,375 INFO sqlalchemy.engine.Engine [cached since 149.3s ago] ('https://www.cnn.com/business/live-news/fox-news-dominion-trial-04-18-23/index.html',)\n",
      "2024-01-30 18:23:44,380 INFO sqlalchemy.engine.Engine COMMIT\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "object has no attribute 'published_parsed'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\feedparser\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    155\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 156\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    157\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\feedparser\\util.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrealkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'published_parsed'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10452/374322848.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mentry\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mentries\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0msummary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'summary'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mprocess_news_article_sync\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpublished_parsed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentry\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\feedparser\\util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    156\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 158\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"object has no attribute '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__hash__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: object has no attribute 'published_parsed'"
     ]
    }
   ],
   "source": [
    "# Use a simple function for processing articles\n",
    "def predict_category(features):\n",
    "    # Placeholder implementation - you should replace this with your actual category prediction logic\n",
    "    return 'unknown'\n",
    "\n",
    "from datetime import datetime\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "\n",
    "def process_news_article_sync(article_id, title, content, pub_date, source_url):\n",
    "    # Convert pub_date to a datetime object if available\n",
    "    pub_date_datetime = None\n",
    "    if pub_date and hasattr(pub_date, 'tm_year'):\n",
    "        pub_date_datetime = datetime(*pub_date[:6])\n",
    "\n",
    "    features = extract_features(title + \" \" + content)\n",
    "    category = predict_category(features)\n",
    "\n",
    "    session = Session()\n",
    "    try:\n",
    "        existing_article = session.query(NewsArticle).get(article_id)\n",
    "        if existing_article:\n",
    "            # Update the existing article\n",
    "            existing_article.title = title\n",
    "            existing_article.content = content\n",
    "            existing_article.pub_date = pub_date_datetime\n",
    "            existing_article.source_url = source_url\n",
    "            existing_article.category = category\n",
    "        else:\n",
    "            # Insert a new article\n",
    "            article = NewsArticle(id=article_id, title=title, content=content, pub_date=pub_date_datetime, source_url=source_url, category=category)\n",
    "            session.add(article)\n",
    "        \n",
    "        session.commit()\n",
    "    except IntegrityError:\n",
    "        # Handle the case where the article already exists (possibly with logging or other actions)\n",
    "        session.rollback()\n",
    "    finally:\n",
    "        session.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process the news feeds synchronously\n",
    "rss_feeds = [\n",
    "    \"http://rss.cnn.com/rss/cnn_topstories.rss\",\n",
    "    \"http://qz.com/feed\",\n",
    "    \"http://feeds.foxnews.com/foxnews/politics\",\n",
    "    \"http://feeds.reuters.com/reuters/businessNews\",\n",
    "    \"http://feeds.feedburner.com/NewshourWorld\",\n",
    "    \"https://feeds.bbci.co.uk/news/world/asia/india/rss.xml\",\n",
    "]\n",
    "\n",
    "for feed_url in rss_feeds:\n",
    "    feed = feedparser.parse(feed_url)\n",
    "    for entry in feed.entries:\n",
    "        summary = entry.get('summary', '')\n",
    "        process_news_article_sync(entry.id, entry.title, summary, entry.published_parsed, entry.link)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22372fd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
